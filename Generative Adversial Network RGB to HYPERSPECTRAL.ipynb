{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKHgf0RtuhRQ"
      },
      "outputs": [],
      "source": [
        "!pip install spectral\n",
        "import tensorflow as tf\n",
        "import spectral\n",
        "import spectral.io.envi as envi\n",
        "import os\n",
        "import pathlib\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "rgb_images = []  \n",
        "hsi_images = []\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the directory path for the hyperspectral images in your Google Drive\n",
        "dir_path = '/content/drive/MyDrive'\n",
        "\n",
        "stop = False\n",
        "\n",
        "for dir_name in os.listdir(dir_path):\n",
        "    if dir_name not in [\"HSI_L\", \"HSI_N\", \"HSI_P\"]:\n",
        "        continue\n",
        "\n",
        "    if (stop):\n",
        "      break\n",
        "\n",
        "    print(f'Processing images in directory {dir_name}...')\n",
        "\n",
        "    if os.path.isdir(os.path.join(dir_path, dir_name)):\n",
        "        # Get the corresponding RGB directory name\n",
        "        rgb_dir_name = dir_name.replace('HSI', 'RGB')\n",
        "\n",
        "        # Loop over all image files in the directory\n",
        "        for file_name in os.listdir(os.path.join(dir_path, dir_name)):\n",
        "            if (len(rgb_images)==2):\n",
        "              stop = True\n",
        "              break\n",
        "\n",
        "            if file_name.endswith('.hdr'):\n",
        "                # Load the HSI image file\n",
        "                hsi_file_path = os.path.join(dir_path, dir_name, file_name)\n",
        "                hsi_image = envi.open(hsi_file_path, hsi_file_path[:-4] + '.raw')\n",
        "\n",
        "                # Preprocess the HSI image\n",
        "                hsi_data = hsi_image.load()\n",
        "                height, width = hsi_image.shape[:2]\n",
        "                hsi_data = hsi_data.reshape(height, width, -1)\n",
        "                hsi_data_min = np.min(hsi_data)\n",
        "                hsi_data_max = np.max(hsi_data)\n",
        "                hsi_data = (hsi_data - hsi_data_min) / (hsi_data_max - hsi_data_min)\n",
        "\n",
        "                # Load the corresponding RGB image file\n",
        "                rgb_file_name = os.path.splitext(file_name)[0] + '.jpg'\n",
        "                rgb_file_path = os.path.join(dir_path, rgb_dir_name, rgb_file_name)\n",
        "                if not os.path.exists(rgb_file_path):\n",
        "                  rgb_file_name = rgb_file_name[:6] + 'C' + rgb_file_name[7:]\n",
        "                  rgb_file_path = os.path.join(dir_path, rgb_dir_name, rgb_file_name)\n",
        "                \n",
        "                if not os.path.exists(rgb_file_path):\n",
        "                  continue\n",
        "                  \n",
        "                rgb_image = cv2.imread(rgb_file_path)\n",
        "                print(rgb_dir_name)\n",
        "                print(rgb_file_name)\n",
        "\n",
        "                # Preprocess the RGB image\n",
        "                rgb_data = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2RGB)\n",
        "                rgb_data = rgb_data.astype(np.float32) / 255.0\n",
        "\n",
        "                # Append the preprocessed HSI and RGB images to their respective lists\n",
        "                hsi_images.append(hsi_data)\n",
        "                rgb_images.append(rgb_data)"
      ],
      "metadata": {
        "id": "Nu9rTKNX9ei3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "def generator(input_shape=(1728, 2304, 3)):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer 1\n",
        "    model.add(Conv2D(64, kernel_size=4, strides=2, padding='same', input_shape=input_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Layer 2\n",
        "    model.add(Conv2D(128, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Layer 3\n",
        "    model.add(Conv2D(256, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Layer 4\n",
        "    model.add(Conv2DTranspose(256, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Layer 5\n",
        "    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Layer 6\n",
        "    model.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Layer 7\n",
        "    model.add(Conv2DTranspose(60, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(60, kernel_size=4, strides=2, padding='same', activation='tanh'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "imD8veX3ulz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = generator()\n",
        "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
      ],
      "metadata": {
        "id": "GTEX6_PD2YbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, LeakyReLU, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "def discriminator(input_shape=(1024, 1280, 60)):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer 1\n",
        "    model.add(Conv2D(64, kernel_size=4, strides=2, padding='same', input_shape=input_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Layer 2\n",
        "    model.add(Conv2D(128, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Layer 3\n",
        "    model.add(Conv2D(256, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Layer 4\n",
        "    model.add(Conv2D(512, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "YHRrZttoy_Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = discriminator()\n",
        "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
      ],
      "metadata": {
        "id": "0ejT1Ztu22ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = loss_object(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = loss_object(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return loss_object(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "LN44cpTL6h_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
      ],
      "metadata": {
        "id": "3QavH9dh6x92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(rgb_images, hsi_images):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(rgb_images, training=True)\n",
        "\n",
        "        real_output = discriminator(hsi_images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    return gen_loss, disc_loss"
      ],
      "metadata": {
        "id": "AQfP12Pj2MQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(rgb_dataset, hsi_dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for rgb_images, hsi_images in zip(rgb_dataset, hsi_dataset):\n",
        "            gen_loss, disc_loss = train_step(rgb_images, hsi_images)\n",
        "\n",
        "       \n",
        "\n",
        "        print(f'Epoch {epoch + 1}, gen_loss={gen_loss:.4f}, disc_loss={disc_loss:.4f}, time={time.time() - start:.2f} sec')\n"
      ],
      "metadata": {
        "id": "AnrsCDxH8Wqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "EPOCHS = 3\n",
        "rgb_images2 = np.array(rgb_images)\n",
        "hsi_images2 = np.array(hsi_images)\n",
        "\n",
        "train(rgb_images2, hsi_images2, EPOCHS)"
      ],
      "metadata": {
        "id": "7Y6wkZc18jRX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}